#!/usr/bin/env python3
"""
Exemplo simples de LangChain com input do usuÃ¡rio via console.
Este script cria um chat bÃ¡sico usando OpenAI que responde Ã s perguntas do usuÃ¡rio.

Para executar:
    pdm run python simple_chat_console.py
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

def main():
    """FunÃ§Ã£o principal que executa o chat interativo."""
    
    # Carrega as variÃ¡veis de ambiente do arquivo .env
    load_dotenv()
    
    # Verifica se a API key do OpenAI estÃ¡ configurada
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key == "your_openai_api_key_here":
        print("âŒ Erro: OPENAI_API_KEY nÃ£o encontrada ou nÃ£o configurada!")
        print("ğŸ“ Configure sua API key no arquivo .env")
        print("ğŸ’¡ Passos:")
        print("   1. cp env.example .env")
        print("   2. Edite o arquivo .env e substitua 'your_openai_api_key_here' pela sua chave real")
        return
    
    try:
        # Inicializa o modelo LLM (OpenAI)
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
            api_key=api_key
        )
        
        print("ğŸ¤– Chat com LangChain - OpenAI")
        print("ğŸ’¬ Digite suas perguntas ou 'sair' para encerrar")
        print("ğŸ”§ Executado com PDM")
        print("-" * 50)
        
        # Mensagem de sistema para definir o comportamento do assistente
        system_message = SystemMessage(
            content="VocÃª Ã© um assistente Ãºtil e amigÃ¡vel. "
                   "Responda de forma clara e concisa Ã s perguntas do usuÃ¡rio em portuguÃªs."
        )
        
        # Loop principal do chat
        while True:
            # Captura input do usuÃ¡rio
            user_input = input("\nğŸ‘¤ VocÃª: ").strip()
            
            # Verifica se o usuÃ¡rio quer sair
            if user_input.lower() in ['sair', 'exit', 'quit', 'bye']:
                print("ğŸ‘‹ AtÃ© logo!")
                break
            
            # Verifica se o input nÃ£o estÃ¡ vazio
            if not user_input:
                print("âš ï¸ Por favor, digite alguma coisa!")
                continue
            
            try:
                # Cria a mensagem do usuÃ¡rio
                human_message = HumanMessage(content=user_input)
                
                # Envia as mensagens para o modelo
                messages = [system_message, human_message]
                
                print("ğŸ¤– Assistente: ", end="", flush=True)
                
                # Chama o modelo e obtÃ©m a resposta
                response = llm.invoke(messages)
                
                # Exibe a resposta
                print(response.content)
                
            except Exception as e:
                print(f"âŒ Erro ao processar sua pergunta: {str(e)}")
                print("ğŸ’¡ Tente novamente ou verifique sua conexÃ£o com a internet")
    
    except Exception as e:
        print(f"âŒ Erro ao inicializar o modelo: {str(e)}")
        print("ğŸ’¡ Verifique sua API key e conexÃ£o com a internet")

if __name__ == "__main__":
    main()
